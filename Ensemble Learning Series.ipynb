{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scratch implementation of blending",
   "id": "7b8aa2b565084f23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T10:28:38.055940Z",
     "start_time": "2024-12-13T10:28:37.991531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sys import implementation\n",
    "\n",
    "import pandas as pd\n",
    "# loading the dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "# Display the first few rows and basic information\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head"
   ],
   "id": "93c521009637efc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       " 0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       " 1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       " 2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       " 3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       " 4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       " \n",
       "   LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       " 0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       " 1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       " 2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       " 3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       " 4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       " \n",
       "   YrSold  SaleType  SaleCondition  SalePrice  \n",
       " 0   2008        WD         Normal     208500  \n",
       " 1   2007        WD         Normal     181500  \n",
       " 2   2008        WD         Normal     223500  \n",
       " 3   2006        WD        Abnorml     140000  \n",
       " 4   2008        WD         Normal     250000  \n",
       " \n",
       " [5 rows x 81 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-13T10:28:38.465589Z",
     "start_time": "2024-12-13T10:28:38.199701Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "# Separate features and target variable\n",
    "X = data.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "y = data[\"SalePrice\"]\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "num_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_transformer, num_cols),\n",
    "        (\"cat\", cat_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to the training and validation data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "\n",
    "X_train_processed.shape, X_val_processed.shape\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 285), (292, 285))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T10:30:29.315002Z",
     "start_time": "2024-12-13T10:30:06.992843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Train individual base models\n",
    "base_models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Fit each base model and make predictions\n",
    "base_predictions_train = []\n",
    "base_predictions_val = []\n",
    "base_mse = {}\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred_train = model.predict(X_train_processed)\n",
    "    y_pred_val = model.predict(X_val_processed)\n",
    "    base_predictions_train.append(y_pred_train)\n",
    "    base_predictions_val.append(y_pred_val)\n",
    "    base_mse[name] = mean_squared_error(y_val, y_pred_val)\n",
    "\n",
    "# Combine base predictions for meta-model training\n",
    "meta_X_train = np.column_stack(base_predictions_train)\n",
    "meta_X_val = np.column_stack(base_predictions_val)\n",
    "\n",
    "# Train a blending model (meta-model)\n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(meta_X_train, y_train)\n",
    "meta_y_pred_val = meta_model.predict(meta_X_val)\n",
    "\n",
    "# Calculate MSE for the blended model\n",
    "blended_mse = mean_squared_error(y_val, meta_y_pred_val)\n",
    "\n",
    "base_mse, blended_mse\n"
   ],
   "id": "32aef88ef4abcbe7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'LinearRegression': np.float64(868803081.0534712),\n",
       "  'DecisionTree': np.float64(1555102828.2465754),\n",
       "  'RandomForest': np.float64(829350970.5694491)},\n",
       " np.float64(1555102828.2465744))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:04:34.671079Z",
     "start_time": "2024-12-13T11:04:32.247463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure data is numeric and handle categorical variables\n",
    "# Assuming X_train and X_val are pandas DataFrames\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, setting invalid entries to NaN\n",
    "X_val = X_val.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values by filling with 0 (can also use imputation)\n",
    "X_train = X_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# Convert target variable (y_train, y_val) to numeric if needed\n",
    "y_train = pd.to_numeric(y_train, errors='coerce').fillna(0)\n",
    "y_val = pd.to_numeric(y_val, errors='coerce').fillna(0)\n",
    "\n",
    "# Train three models\n",
    "model1 = LinearRegression()\n",
    "model2 = DecisionTreeRegressor(random_state=42)\n",
    "model3 = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on validation set\n",
    "pred1 = model1.predict(X_val)\n",
    "pred2 = model2.predict(X_val)\n",
    "pred3 = model3.predict(X_val)\n",
    "\n",
    "# Blending (average predictions)\n",
    "blended_pred = (pred1 + pred2 + pred3) / 3\n",
    "\n",
    "# Calculate MSE for each model and the blended model\n",
    "mse_model1 = mean_squared_error(y_val, pred1)\n",
    "mse_model2 = mean_squared_error(y_val, pred2)\n",
    "mse_model3 = mean_squared_error(y_val, pred3)\n",
    "mse_blended = mean_squared_error(y_val, blended_pred)\n",
    "\n",
    "print(\"MSE Model for Linear Regression:\", mse_model1)\n",
    "print(\"MSE Model for SVR:\", mse_model2)\n",
    "print(\"MSE Model for Decision Tree Regressor:\", mse_model3)\n",
    "print(\"MSE for Blended Model\", mse_blended)\n",
    "\n",
    "# comparing to see if blending outperforms individual models\n",
    "if mse_blended < min(mse_model1, mse_model2, mse_model3):\n",
    "    print(\"Blending improved the accuracy compared to the individual models\")\n",
    "else:\n",
    "    print(\"Blending failed to improve the accuracy\")"
   ],
   "id": "d698cbf7fd3b4e8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Model for Linear Regression: 1300424286.328339\n",
      "MSE Model for SVR: 1579668220.3630137\n",
      "MSE Model for Decision Tree Regressor: 874893796.5472958\n",
      "MSE for Blended Model 946755614.3439462\n",
      "Blending failed to improve the accuracy\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scratch implementation of bagging",
   "id": "33df38e6aaaed7e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T11:37:52.703316Z",
     "start_time": "2024-12-13T11:37:52.488668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# loading the dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Ensure no missing values in the selected columns\n",
    "data_cleaned = data[['GrLivArea', 'YearBuilt', 'SalePrice']].dropna()\n",
    "\n",
    "# Select features and target\n",
    "X = data_cleaned[['GrLivArea', 'YearBuilt']]\n",
    "y = data_cleaned['SalePrice']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# bagging implementation with corrected signature\n",
    "def bagging(X_train, y_train, X_val, base_model, n_estimators=15):\n",
    "    predictions = np.zeros((X_val.shape[0], n_estimators))\n",
    "    for i in range(n_estimators):\n",
    "        # Random sampling with replacement\n",
    "        idx = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_sample, y_sample = X_train.iloc[idx], y_train.iloc[idx]\n",
    "\n",
    "        # Training the base model\n",
    "        model = base_model()\n",
    "        model.fit(X_sample, y_sample)\n",
    "\n",
    "        # Storing the predictions\n",
    "        predictions[:, i] = model.predict(X_val)\n",
    "    # Averaging predictions across all models\n",
    "    final_prediction = predictions.mean(axis=1)\n",
    "    return final_prediction\n",
    "\n",
    "# base model for bagging\n",
    "base_model = DecisionTreeRegressor\n",
    "\n",
    "# applying the bagging model\n",
    "n_estimators = 15\n",
    "bagged_predictions = bagging(X_train, y_train, X_val, base_model, n_estimators)\n",
    "# evaluating the bagging model\n",
    "mse_bagging = mean_squared_error(y_val, bagged_predictions)\n",
    "# comparing with a single decision tree model\n",
    "single_model = base_model()\n",
    "single_model.fit(X_train, y_train)\n",
    "single_prediction = single_model.predict(X_val)\n",
    "mse_single = mean_squared_error(y_val, single_prediction)\n",
    "\n",
    "# outputting the results\n",
    "print(f'MSE for single Decision Tree: {mse_single}')\n",
    "print(f'MSE for Bagging with {n_estimators} Decision Trees: {mse_bagging}')\n",
    "\n",
    "if mse_bagging < mse_single:\n",
    "    print('Bagging improved the accuracy.')\n",
    "    print('Bagging did not improve the accuracy.')"
   ],
   "id": "830a95de21b3af1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for single Decision Tree: 2289084434.8813734\n",
      "MSE for Bagging with 15 Decision Trees: 1679400820.5945714\n",
      "Bagging improved the accuracy.\n",
      "Bagging did not improve the accuracy.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scratch implementation of stacking",
   "id": "154f5938065905d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T12:09:30.675286Z",
     "start_time": "2024-12-13T12:09:29.660024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Select explanatory variables and dependent variable\n",
    "X = data[[\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = data[\"SalePrice\"]\n",
    "\n",
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Stacking implementation\n",
    "def stacking(X_train, y_train, X_val, base_models, meta_model, n_folds=5):\n",
    "    # Step 1: Generate blended data for training (Stage 0)\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    base_train_predictions = np.zeros((X_train.shape[0], len(base_models)))  # For Stage 1 training\n",
    "    base_test_predictions = np.zeros((X_val.shape[0], len(base_models)))    # For final prediction\n",
    "    for i, model in enumerate(base_models):\n",
    "        fold_predictions = np.zeros((X_val.shape[0], n_folds))\n",
    "        for j, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            # Split the training data into folds\n",
    "            X_train_fold, y_train_fold = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "            X_val_fold, y_val_fold = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            # Train the base model on (K-1) folds\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict on the validation fold\n",
    "            base_train_predictions[val_idx, i] = model.predict(X_val_fold)\n",
    "\n",
    "            # Predict on the test set for this fold\n",
    "            fold_predictions[:, j] = model.predict(X_val)\n",
    "\n",
    "        # Average predictions across all folds for the test set\n",
    "        base_test_predictions[:, i] = fold_predictions.mean(axis=1)\n",
    "\n",
    "    # Step 2: Train the meta-model (Stage 1)\n",
    "    meta_model.fit(base_train_predictions, y_train)\n",
    "\n",
    "    # Step 3: Predict on the test set using the meta-model\n",
    "    final_predictions = meta_model.predict(base_test_predictions)\n",
    "\n",
    "    return final_predictions\n",
    "# Define base models\n",
    "base_models = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    SVR(kernel=\"linear\")\n",
    "]\n",
    "\n",
    "# Define meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Apply stacking\n",
    "stacked_predictions = stacking(X_train, y_train, X_val, base_models, meta_model, n_folds=5)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "mse_stacking = mean_squared_error(y_val, stacked_predictions)\n",
    "\n",
    "# Compare with a single model (e.g., Linear Regression)\n",
    "single_model = LinearRegression()\n",
    "single_model.fit(X_train, y_train)\n",
    "single_predictions = single_model.predict(X_val)\n",
    "mse_single = mean_squared_error(y_val, single_predictions)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Squared Error for Single Model (Linear Regression): {mse_single}\")\n",
    "print(f\"Mean Squared Error for Stacking Model: {mse_stacking}\")\n",
    "\n",
    "if mse_stacking < mse_single:\n",
    "    print(\"Stacking improved the accuracy!\")\n",
    "else:\n",
    "    print(\"Stacking did not improve the accuracy.\")"
   ],
   "id": "fd0a36fa5b4d126e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Single Model (Linear Regression): 2495554898.6683216\n",
      "Mean Squared Error for Stacking Model: 1938950737.699865\n",
      "Stacking improved the accuracy!\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
